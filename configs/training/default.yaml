# @package _global_

# Training configuration
training:
  # Basic training settings
  epochs: 200
  first_epoch_gmm: 50
  refit_gmm_interval: 100
  lambda_gmm: 1.0
  
  # Optimization settings
  optimizer:
    decoder:
      type: "AdamW"
      lr: 0.001
      weight_decay: 0.01
      
    representation:
      type: "AdamW" 
      lr: 0.01
      weight_decay: 0.01
      
  # Learning rate scheduling
  scheduler:
    type: "CosineAnnealingLR"
    T_max: 200
    eta_min: 1e-6
    
  # Early stopping
  early_stopping:
    enabled: false
    patience: 20
    min_delta: 1e-4
    metric: "total_loss"
    mode: "min"
    
  # Checkpointing
  checkpointing:
    enabled: true
    save_best: true
    save_last: true
    save_interval: 50
    
  # Logging and visualization
  logging:
    log_interval: 10
    plot_interval: 50
    save_figures: true
    
  # Validation
  validation:
    enabled: true
    interval: 1
