# Default configuration for ImageDGD training
# This configuration provides reasonable defaults for production training

# General settings
random_seed: 42
experiment_name: "ImageDGD_Default"
description: "Default ImageDGD training configuration"

# Data configuration
data:
  dataset: "FashionMNIST"  # Options: "FashionMNIST", "MNIST", "CIFAR10"
  data_dir: "./data"
  batch_size: 128
  num_workers: 4
  pin_memory: true
  use_subset: false
  subset_fraction: 1.0
  normalize: true
  
# Model configuration
model:
  # Representation layer configuration
  representation:
    n_features: 32  # Latent dimension
    distribution: "uniform"  # Options: "uniform", "normal", "beta", "gamma"
    radius: 1.0  # For uniform distribution
  
  # Decoder configuration
  decoder:
    hidden_dims: [512, 256, 128, 64, 32]
    output_channels: 1  # 1 for grayscale, 3 for RGB
    output_size: [28, 28]
    init_size: [4, 4]
    kernel_size: 3
    stride: 2
    padding: 1
    output_padding: 1
    bias: true
    normalization: "batch"  # Options: "batch", "group", "layer", "instance", "none"
    use_batch_norm: true  # Deprecated, use normalization
    activation: "leaky_relu"  # See ConvDecoder for all options
    final_activation: "sigmoid"
    dropout_rate: 0.0
    upsampling_mode: "transpose"  # Options: "transpose", "nearest", "bilinear", "bicubic"
    use_spectral_norm: false
    use_self_attention: false
    attention_resolution: 32
  
  # GMM configuration
  gmm:
    n_components: 10
    covariance_type: "full"  # Options: "full", "tied", "diag", "spherical"
    init_params: "kmeans"  # Options: "kmeans", "random"
    verbose: false
    max_iter: 1000
    tol: 1e-3
    n_init: 10
    warm_start: false

# Training configuration
training:
  epochs: 200
  device: "auto"  # Options: "auto", "cpu", "cuda", "cuda:0", etc.
  
  # GMM training schedule
  first_epoch_gmm: 50
  refit_gmm_interval: 25
  lambda_gmm: 1.0
  
  # Optimizer configuration
  optimizer:
    decoder:
      type: "AdamW"
      lr: 0.001
      weight_decay: 0.0  # No weight decay for decoder (recommended)
      betas: [0.9, 0.999]
      eps: 1e-8
    representation:
      type: "AdamW"
      lr: 0.01  # Higher learning rate for representations
      weight_decay: 0.01
      betas: [0.9, 0.999]
      eps: 1e-8
  
  # Logging configuration
  logging:
    log_interval: 10  # Log every N epochs
    plot_interval: 25  # Create plots every N epochs
    save_figures: true
    figure_format: "png"
    dpi: 150

# ClearML configuration
clearml:
  enabled: true
  project_name: "ImageDGD"
  task_name: "Default_Training"
  tags: ["default", "production"]
  
# Hardware configuration
hardware:
  mixed_precision: false
  compile_model: false  # PyTorch 2.0 model compilation
  benchmark_cudnn: true