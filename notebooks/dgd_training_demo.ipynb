{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38007b1f",
   "metadata": {},
   "source": [
    "# DGD Training Demo: Using the DGDTrainer Class\n",
    "\n",
    "This notebook demonstrates the complete usage of the DGDTrainer class from `src/training/trainer.py`. We'll train a Deep Generative Decoder (DGD) model on the FashionMNIST dataset using the standard production configuration, showcasing:\n",
    "\n",
    "- Configuration setup using Hydra/OmegaConf with the standard config\n",
    "- Dataset preparation and data loading\n",
    "- ClearML integration for experiment tracking\n",
    "- Model training with representation layers and GMM fitting\n",
    "- Visualization of training progress and results\n",
    "- Model evaluation and sample generation\n",
    "- Model saving and loading\n",
    "\n",
    "The DGD model combines:\n",
    "- **Representation Layer**: Learnable per-sample embeddings in latent space\n",
    "- **Convolutional Decoder**: Neural network that maps latent codes to images\n",
    "- **Gaussian Mixture Model**: Probabilistic model fitted to the learned representations\n",
    "\n",
    "**Note**: This demo uses the standard production configuration for full model capacity. If you have limited GPU memory, you can uncomment the memory optimization lines in the configuration section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2799b51",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Imports\n",
    "\n",
    "First, let's import all necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a219d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data science and ML libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Configuration management\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "# Experiment tracking\n",
    "from clearml import Task\n",
    "\n",
    "# Add project root to path for imports\n",
    "current_dir = Path.cwd()\n",
    "if 'notebooks' in current_dir.parts:\n",
    "    # We're in the notebooks folder, go up one level\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Import our custom modules\n",
    "from src.training.trainer import DGDTrainer\n",
    "from src.data.dataloader import create_dataloaders, get_sample_batches\n",
    "from src.models import RepresentationLayer, DGD, ConvDecoder, GaussianMixture\n",
    "from src.visualization import plot_training_losses, plot_images\n",
    "\n",
    "# Set device and apply memory optimizations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Apply CUDA memory optimizations for local training\n",
    "if torch.cuda.is_available():\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Set memory management optimizations\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Enable memory-efficient attention if available\n",
    "    try:\n",
    "        torch.backends.cuda.enable_flash_sdp(False)  # Disable for compatibility\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"✓ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"✓ Applied CUDA memory optimizations\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"✓ Memory optimizations applied for local training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8c251",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n",
    "\n",
    "Load the training configuration using Hydra/OmegaConf. We'll use the standard production configuration which provides full model capacity and training settings. You can optionally apply memory optimizations if running on limited hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea755ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from the config directory\n",
    "config_dir = project_root / \"config\"\n",
    "print(f\"Loading configuration from: {config_dir}\")\n",
    "\n",
    "# For Hydra initialize, we need to provide a relative path from the current working directory\n",
    "# Since we're in the notebooks folder, the config folder is ../config\n",
    "relative_config_path = \"../config\"\n",
    "\n",
    "# Initialize Hydra with the relative config directory\n",
    "with initialize(version_base=None, config_path=relative_config_path):\n",
    "    # Use the standard config for full training capabilities\n",
    "    config = compose(config_name=\"config\")\n",
    "\n",
    "print(\"✓ Configuration loaded successfully!\")\n",
    "print(f\"✓ Experiment: {config.experiment_name}\")\n",
    "print(f\"✓ Dataset: {config.data.dataset}\")\n",
    "print(f\"✓ Training epochs: {config.training.epochs}\")\n",
    "print(f\"✓ Batch size: {config.data.batch_size}\")\n",
    "print(f\"✓ Latent dimensions: {config.model.representation.n_features}\")\n",
    "\n",
    "# Optional: Apply some memory optimizations for local training if needed\n",
    "print(\"\\n🔧 Optional memory optimizations (uncomment if needed for limited GPU memory)...\")\n",
    "\n",
    "# Uncomment these lines if you need to reduce memory usage:\n",
    "# config.data.batch_size = 64  # Reduce batch size\n",
    "# config.data.subset_fraction = 0.2  # Use subset of data\n",
    "# config.training.epochs = 50  # Fewer epochs\n",
    "# config.model.decoder.hidden_dims = [256, 128, 64]  # Smaller network\n",
    "# config.model.representation.n_features = 16   # Smaller latent space\n",
    "# config.model.gmm.n_components = 5  # Fewer GMM components\n",
    "# config.training.logging.save_figures = False  # Save memory\n",
    "\n",
    "print(\"✓ Using standard configuration:\")\n",
    "print(f\"  - Batch size: {config.data.batch_size}\")\n",
    "print(f\"  - Data subset: {'Yes' if config.data.use_subset else 'No'} ({config.data.subset_fraction:.1%} if subset)\")\n",
    "print(f\"  - Epochs: {config.training.epochs}\")\n",
    "print(f\"  - Latent dims: {config.model.representation.n_features}\")\n",
    "print(f\"  - Decoder dims: {list(config.model.decoder.hidden_dims)}\")\n",
    "print(f\"  - GMM components: {config.model.gmm.n_components}\")\n",
    "\n",
    "# Display key configuration sections\n",
    "print(\"\\n🔧 Model Configuration:\")\n",
    "print(f\"  Representation: {config.model.representation.distribution} distribution\")\n",
    "print(f\"  Latent dims: {config.model.representation.n_features}\")\n",
    "print(f\"  Decoder hidden dims: {list(config.model.decoder.hidden_dims)}\")\n",
    "print(f\"  GMM components: {config.model.gmm.n_components}\")\n",
    "print(f\"  Output size: {config.model.decoder.output_size}\")\n",
    "\n",
    "print(\"\\n🎯 Training Configuration:\")\n",
    "print(f\"  Decoder optimizer: {config.training.optimizer.decoder.type}\")\n",
    "print(f\"  Representation optimizer: {config.training.optimizer.representation.type}\")\n",
    "print(f\"  Learning rates: decoder={config.training.optimizer.decoder.lr}, rep={config.training.optimizer.representation.lr}\")\n",
    "print(f\"  GMM starts at epoch: {config.training.first_epoch_gmm}\")\n",
    "print(f\"  Refit GMM interval: {config.training.refit_gmm_interval}\")\n",
    "print(f\"  Lambda GMM: {config.training.lambda_gmm}\")\n",
    "\n",
    "print(\"\\n📊 Data Configuration:\")\n",
    "print(f\"  Dataset: {config.data.dataset}\")\n",
    "print(f\"  Batch size: {config.data.batch_size}\")\n",
    "print(f\"  Use subset: {config.data.use_subset}\")\n",
    "print(f\"  Subset fraction: {config.data.subset_fraction}\")\n",
    "print(f\"  Number of workers: {config.data.num_workers}\")\n",
    "\n",
    "print(\"\\n💾 Using Standard Production Configuration:\")\n",
    "print(\"  ✓ Full dataset (unless subset enabled)\")\n",
    "print(\"  ✓ Larger model architecture\")\n",
    "print(\"  ✓ More training epochs\")\n",
    "print(\"  ✓ More GMM components\")\n",
    "print(\"  ✓ Production-ready settings\")\n",
    "print(\"  ✓ Better model capacity and performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c6782",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset and Data Loaders\n",
    "\n",
    "Load and prepare the FashionMNIST dataset with proper transformations and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories\n",
    "data_dir = project_root / \"data\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "# OmegaConf is in struct mode, so we need to disable it to add new fields\n",
    "OmegaConf.set_struct(config, False)  # Disable struct mode temporarily\n",
    "\n",
    "# Update the config to work with the dataloader function\n",
    "config.data.data_dir = str(data_dir)\n",
    "config.data.download = True\n",
    "\n",
    "# Define class names for FashionMNIST\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "# Update the class names in config\n",
    "config.data.class_names = class_names\n",
    "\n",
    "# Re-enable struct mode if desired\n",
    "OmegaConf.set_struct(config, True)\n",
    "\n",
    "print(\"✓ Configuration updated for FashionMNIST dataset\")\n",
    "\n",
    "# Create data loaders using our custom dataloader function\n",
    "print(\"Loading dataset and creating data loaders...\")\n",
    "train_loader, test_loader, loaded_class_names = create_dataloaders(config)\n",
    "\n",
    "print(f\"✓ Train loader: {len(train_loader)} batches\")\n",
    "print(f\"✓ Test loader: {len(test_loader)} batches\")\n",
    "print(f\"✓ Classes: {loaded_class_names}\")\n",
    "\n",
    "# Prepare sample data for visualization using the new function\n",
    "sample_data = get_sample_batches(train_loader, test_loader, n_samples=16)\n",
    "print(f\"✓ Prepared sample data for visualization\")\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "fig.suptitle('Sample Images from FashionMNIST', fontsize=16)\n",
    "\n",
    "for i in range(8):\n",
    "    # Train samples\n",
    "    img = sample_data[1][i].squeeze()\n",
    "    label = sample_data[2][i].item()\n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'Train: {class_names[label]}', fontsize=8)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Test samples  \n",
    "    img = sample_data[4][i].squeeze()\n",
    "    label = sample_data[5][i].item()\n",
    "    axes[1, i].imshow(img, cmap='gray')\n",
    "    axes[1, i].set_title(f'Test: {class_names[label]}', fontsize=8)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Dataset Summary:\")\n",
    "print(f\"  Input shape: {sample_data[1][0].shape}\")\n",
    "print(f\"  Number of classes: {len(class_names)}\")\n",
    "print(f\"  Classes: {class_names}\")\n",
    "print(f\"  Sample data shapes: train={len(sample_data[1])}, test={len(sample_data[4])}\")\n",
    "print(f\"  Value range: [{sample_data[1].min():.2f}, {sample_data[1].max():.2f}] (normalized to [-1,1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3a43a",
   "metadata": {},
   "source": [
    "## 4. Initialize ClearML Task\n",
    "\n",
    "Set up ClearML for experiment tracking. This will log all training metrics, configurations, and artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ClearML task for experiment tracking\n",
    "print(\"Initializing ClearML task...\")\n",
    "\n",
    "try:\n",
    "    # Create a task for this training session\n",
    "    task = Task.init(\n",
    "        project_name=\"ImageDGD\", \n",
    "        task_name=f\"DGD Training Demo - {config.model.representation.distribution}\",\n",
    "        tags=[\"demo\", \"notebook\", config.data.dataset, f\"{config.training.epochs}epochs\"]\n",
    "    )\n",
    "    \n",
    "    # Connect the configuration to ClearML\n",
    "    task.connect(config)\n",
    "    \n",
    "    # Set task description\n",
    "    task.set_comment(\"\"\"\n",
    "    DGD Training Demo using DGDTrainer class.\n",
    "    \n",
    "    This experiment demonstrates:\n",
    "    - Deep Generative Decoder training\n",
    "    - Representation layer learning\n",
    "    - GMM fitting in latent space\n",
    "    - Training visualization and monitoring\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"✓ ClearML task initialized successfully!\")\n",
    "    print(f\"✓ Project: ImageDGD\")\n",
    "    print(f\"✓ Task: DGD Training Demo - {config.model.representation.distribution}\")\n",
    "    print(f\"✓ Task ID: {task.id}\")\n",
    "    \n",
    "    # Get dataset sizes from the data loaders\n",
    "    train_dataset_size = len(train_loader.dataset)\n",
    "    test_dataset_size = len(test_loader.dataset)\n",
    "    \n",
    "    # Log some initial parameters\n",
    "    task.set_parameters({\n",
    "        \"dataset_size_train\": train_dataset_size,\n",
    "        \"dataset_size_test\": test_dataset_size,\n",
    "        \"device\": str(device),\n",
    "        \"pytorch_version\": torch.__version__,\n",
    "        \"subset_used\": config.data.use_subset,\n",
    "        \"subset_fraction\": config.data.subset_fraction if config.data.use_subset else None\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ClearML initialization failed: {e}\")\n",
    "    print(\"⚠️ Continuing without ClearML tracking...\")\n",
    "    task = None\n",
    "\n",
    "print(\"\\\\n📝 Experiment Configuration:\")\n",
    "print(f\"  Project: ImageDGD\")\n",
    "print(f\"  Task: DGD Training Demo\")\n",
    "print(f\"  Dataset: {config.data.dataset}\")\n",
    "print(f\"  Model: DGD (Deep Generative Decoder)\")  # Fixed: removed non-existent config.model.type\n",
    "print(f\"  Distribution: {config.model.representation.distribution}\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Tracking: {'ClearML' if task else 'Local only'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a860ece",
   "metadata": {},
   "source": [
    "## 5. Create and Configure Trainer\n",
    "\n",
    "Now let's instantiate the DGDTrainer with our configuration and device settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DGDTrainer instance\n",
    "print(\"Creating DGDTrainer...\")\n",
    "\n",
    "trainer = DGDTrainer(\n",
    "    config=config,\n",
    "    device=device,\n",
    "    verbose=True  # Enable detailed logging\n",
    ")\n",
    "\n",
    "print(\"✓ DGDTrainer created successfully!\")\n",
    "\n",
    "# The trainer will automatically handle:\n",
    "# - Model component creation (decoder, representation layers, GMM)\n",
    "# - Optimizer setup based on configuration\n",
    "# - Loss computation and tracking\n",
    "# - Visualization generation\n",
    "# - ClearML logging integration\n",
    "\n",
    "print(\"\\\\n🔧 Trainer Configuration:\")\n",
    "print(f\"  Device: {trainer.device}\")\n",
    "print(f\"  Verbose mode: {trainer.verbose}\")\n",
    "print(f\"  Training config: {trainer.training_config.epochs} epochs\")\n",
    "print(f\"  GMM starts at epoch: {trainer.training_config.first_epoch_gmm}\")\n",
    "print(f\"  Lambda GMM: {trainer.training_config.lambda_gmm}\")\n",
    "print(f\"  Log interval: {trainer.training_config.logging.log_interval}\")\n",
    "print(f\"  Plot interval: {trainer.training_config.logging.plot_interval}\")\n",
    "print(f\"  Save figures: {trainer.training_config.logging.save_figures}\")\n",
    "\n",
    "print(\"\\\\n📊 Optimizer Configuration:\")\n",
    "print(f\"  Decoder optimizer: {config.training.optimizer.decoder.type}\")\n",
    "print(f\"    - Learning rate: {config.training.optimizer.decoder.lr}\")\n",
    "print(f\"    - Weight decay: {config.training.optimizer.decoder.weight_decay}\")\n",
    "print(f\"  Representation optimizer: {config.training.optimizer.representation.type}\")\n",
    "print(f\"    - Learning rate: {config.training.optimizer.representation.lr}\")\n",
    "print(f\"    - Weight decay: {config.training.optimizer.representation.weight_decay}\")\n",
    "\n",
    "print(\"\\\\n🏗️ Model Architecture:\")\n",
    "print(f\"  Representation dimension: {config.model.representation.n_features}\")\n",
    "print(f\"  Distribution type: {config.model.representation.distribution}\")\n",
    "print(f\"  Decoder hidden dims: {list(config.model.decoder.hidden_dims)}\")\n",
    "print(f\"  Decoder activation: {config.model.decoder.activation}\")\n",
    "print(f\"  Decoder final activation: {config.model.decoder.final_activation}\")\n",
    "print(f\"  GMM components: {config.model.gmm.n_components}\")\n",
    "print(f\"  GMM covariance type: {config.model.gmm.covariance_type}\")\n",
    "\n",
    "print(\"\\\\n✅ Trainer is ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2ecc1",
   "metadata": {},
   "source": [
    "## 6. Run Training Process\n",
    "\n",
    "Now let's start the training! The trainer will handle everything including model creation, optimization, GMM fitting, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "print(\"🚀 Starting DGD training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Record start time\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Run the training process\n",
    "# The trainer.train() method handles:\n",
    "# - Model component creation (decoder, representation layers, GMM)\n",
    "# - Optimizer setup and configuration\n",
    "# - Training loop with progress tracking\n",
    "# - GMM fitting at specified intervals\n",
    "# - Loss computation and logging\n",
    "# - Visualization generation and saving\n",
    "# - ClearML metric logging\n",
    "\n",
    "try:\n",
    "    results = trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        sample_data=sample_data,\n",
    "        class_names=class_names\n",
    "    )\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    total_training_time = training_end_time - training_start_time\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 Training completed successfully!\")\n",
    "    print(f\"⏱️ Total training time: {total_training_time:.2f} seconds ({total_training_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # Extract results\n",
    "    model = results['model']\n",
    "    rep_layer = results['rep']\n",
    "    test_rep_layer = results['test_rep']\n",
    "    gmm = results['gmm']\n",
    "    train_losses = results['train_losses']\n",
    "    test_losses = results['test_losses']\n",
    "    \n",
    "    print(f\"\\\\n📊 Final Results:\")\n",
    "    print(f\"  Final train loss: {results['final_train_loss']:.6f}\")\n",
    "    print(f\"  Final test loss: {results['final_test_loss']:.6f}\")\n",
    "    print(f\"  Best train loss: {min(train_losses):.6f} (epoch {train_losses.index(min(train_losses)) + 1})\")\n",
    "    print(f\"  Best test loss: {min(test_losses):.6f} (epoch {test_losses.index(min(test_losses)) + 1})\")\n",
    "    \n",
    "    # Model information\n",
    "    decoder_params = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)\n",
    "    rep_params = sum(p.numel() for p in rep_layer.parameters() if p.requires_grad)\n",
    "    test_rep_params = sum(p.numel() for p in test_rep_layer.parameters() if p.requires_grad)\n",
    "    total_params = decoder_params + rep_params + test_rep_params\n",
    "    \n",
    "    print(f\"\\\\n🏗️ Model Statistics:\")\n",
    "    print(f\"  Decoder parameters: {decoder_params:,} ({decoder_params/1e6:.2f}M)\")\n",
    "    print(f\"  Train representation parameters: {rep_params:,} ({rep_params/1e6:.2f}M)\")\n",
    "    print(f\"  Test representation parameters: {test_rep_params:,} ({test_rep_params/1e6:.2f}M)\")\n",
    "    print(f\"  Total parameters: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
    "    \n",
    "    print(f\"\\\\n🎯 GMM Information:\")\n",
    "    print(f\"  Number of components: {gmm.n_components}\")\n",
    "    print(f\"  Covariance type: {gmm.covariance_type}\")\n",
    "    print(f\"  Converged: {gmm.converged_}\")\n",
    "    print(f\"  Number of iterations: {gmm.n_iter_}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise e\n",
    "\n",
    "print(\"\\\\n✅ Training phase completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ee0b4",
   "metadata": {},
   "source": [
    "## 7. Analyze Training Results\n",
    "\n",
    "Let's analyze the training results by examining loss curves, reconstruction quality, and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adedba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive training analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('DGD Training Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Training and Test Loss\n",
    "axes[0, 0].plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(range(1, len(test_losses) + 1), test_losses, 'r-', label='Test Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Test Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Reconstruction Losses\n",
    "recon_train_losses = trainer.recon_train_losses\n",
    "recon_test_losses = trainer.recon_test_losses\n",
    "axes[0, 1].plot(range(1, len(recon_train_losses) + 1), recon_train_losses, 'g-', label='Train Reconstruction', linewidth=2)\n",
    "axes[0, 1].plot(range(1, len(recon_test_losses) + 1), recon_test_losses, 'orange', label='Test Reconstruction', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Reconstruction Loss')\n",
    "axes[0, 1].set_title('Reconstruction Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. GMM Losses (after GMM starts)\n",
    "gmm_train_losses = trainer.gmm_train_losses\n",
    "gmm_test_losses = trainer.gmm_test_losses\n",
    "gmm_start_epoch = config.training.first_epoch_gmm\n",
    "\n",
    "if len(gmm_train_losses) > 0 and any(x != 0 for x in gmm_train_losses):\n",
    "    non_zero_epochs = [i+1 for i, x in enumerate(gmm_train_losses) if x != 0]\n",
    "    non_zero_train = [x for x in gmm_train_losses if x != 0]\n",
    "    non_zero_test = [gmm_test_losses[i] for i, x in enumerate(gmm_train_losses) if x != 0]\n",
    "    \n",
    "    axes[0, 2].plot(non_zero_epochs, non_zero_train, 'purple', label='Train GMM Loss', linewidth=2)\n",
    "    axes[0, 2].plot(non_zero_epochs, non_zero_test, 'brown', label='Test GMM Loss', linewidth=2)\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('GMM Loss')\n",
    "    axes[0, 2].set_title(f'GMM Loss (starts epoch {gmm_start_epoch})')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[0, 2].text(0.5, 0.5, 'GMM not fitted yet\\\\nor no GMM loss', ha='center', va='center', transform=axes[0, 2].transAxes)\n",
    "    axes[0, 2].set_title('GMM Loss')\n",
    "\n",
    "# 4. Loss Improvement Rate\n",
    "if len(train_losses) > 1:\n",
    "    train_improvements = [((train_losses[i-1] - train_losses[i]) / train_losses[i-1] * 100) if train_losses[i-1] != 0 else 0 \n",
    "                         for i in range(1, len(train_losses))]\n",
    "    test_improvements = [((test_losses[i-1] - test_losses[i]) / test_losses[i-1] * 100) if test_losses[i-1] != 0 else 0 \n",
    "                        for i in range(1, len(test_losses))]\n",
    "    \n",
    "    axes[1, 0].plot(range(2, len(train_losses) + 1), train_improvements, 'b-', label='Train Improvement %', linewidth=2)\n",
    "    axes[1, 0].plot(range(2, len(test_losses) + 1), test_improvements, 'r-', label='Test Improvement %', linewidth=2)\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Improvement (%)')\n",
    "    axes[1, 0].set_title('Loss Improvement Rate')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Epoch Times\n",
    "epoch_times = trainer.epoch_times\n",
    "if len(epoch_times) > 0:\n",
    "    axes[1, 1].plot(range(1, len(epoch_times) + 1), epoch_times, 'green', linewidth=2)\n",
    "    axes[1, 1].axhline(y=np.mean(epoch_times), color='red', linestyle='--', label=f'Avg: {np.mean(epoch_times):.2f}s')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Time (seconds)')\n",
    "    axes[1, 1].set_title('Training Time per Epoch')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Loss Summary Statistics\n",
    "train_mean = np.mean(train_losses)\n",
    "train_std = np.std(train_losses)\n",
    "test_mean = np.mean(test_losses)\n",
    "test_std = np.std(test_losses)\n",
    "\n",
    "stats_text = f\"\"\"Training Statistics:\n",
    "\n",
    "Train Loss:\n",
    "  Mean: {train_mean:.6f}\n",
    "  Std:  {train_std:.6f}\n",
    "  Min:  {min(train_losses):.6f}\n",
    "  Max:  {max(train_losses):.6f}\n",
    "\n",
    "Test Loss:\n",
    "  Mean: {test_mean:.6f}\n",
    "  Std:  {test_std:.6f}\n",
    "  Min:  {min(test_losses):.6f}\n",
    "  Max:  {max(test_losses):.6f}\n",
    "\n",
    "Improvement:\n",
    "  Train: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%\n",
    "  Test:  {((test_losses[0] - test_losses[-1]) / test_losses[0] * 100):.2f}%\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 2].text(0.05, 0.95, stats_text, transform=axes[1, 2].transAxes, fontsize=10, \n",
    "                verticalalignment='top', fontfamily='monospace')\n",
    "axes[1, 2].set_title('Training Statistics')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Training Analysis Complete!\")\n",
    "print(f\"✓ Total epochs: {len(train_losses)}\")\n",
    "print(f\"✓ Training improvement: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%\")\n",
    "print(f\"✓ Test improvement: {((test_losses[0] - test_losses[-1]) / test_losses[0] * 100):.2f}%\")\n",
    "print(f\"✓ Average epoch time: {np.mean(epoch_times):.2f} seconds\")\n",
    "print(f\"✓ GMM fitted: {'Yes' if gmm.converged_ else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7860c4",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Testing\n",
    "\n",
    "Let's evaluate the trained model by examining reconstruction quality and computing various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "print(\"🔍 Evaluating trained DGD model...\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Test reconstruction quality on sample data\n",
    "with torch.no_grad():\n",
    "    # Get sample data\n",
    "    indices_train, images_train, labels_train, indices_test, images_test, labels_test = sample_data\n",
    "    \n",
    "    # Move to device\n",
    "    indices_train = indices_train.to(device)\n",
    "    images_train = images_train.to(device)\n",
    "    indices_test = indices_test.to(device)\n",
    "    images_test = images_test.to(device)\n",
    "    \n",
    "    # Generate reconstructions\n",
    "    z_train = rep_layer(indices_train)\n",
    "    recon_train = model.decoder(z_train)\n",
    "    \n",
    "    z_test = test_rep_layer(indices_test)\n",
    "    recon_test = model.decoder(z_test)\n",
    "    \n",
    "    # Compute reconstruction errors\n",
    "    train_mse = F.mse_loss(recon_train, images_train, reduction='none').mean(dim=[1,2,3])\n",
    "    test_mse = F.mse_loss(recon_test, images_test, reduction='none').mean(dim=[1,2,3])\n",
    "    \n",
    "    print(f\"✓ Reconstruction MSE - Train: {train_mse.mean():.6f} ± {train_mse.std():.6f}\")\n",
    "    print(f\"✓ Reconstruction MSE - Test: {test_mse.mean():.6f} ± {test_mse.std():.6f}\")\n",
    "\n",
    "# Visualize reconstructions\n",
    "fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
    "fig.suptitle('Model Evaluation: Original vs Reconstructed Images', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Convert tensors to CPU and numpy for plotting\n",
    "images_train_cpu = images_train.cpu()\n",
    "recon_train_cpu = recon_train.cpu()\n",
    "images_test_cpu = images_test.cpu()\n",
    "recon_test_cpu = recon_test.cpu()\n",
    "labels_train_cpu = labels_train.cpu()\n",
    "labels_test_cpu = labels_test.cpu()\n",
    "\n",
    "for i in range(8):\n",
    "    # Original train images\n",
    "    img = images_train_cpu[i].squeeze()\n",
    "    img = (img + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "    label = labels_train_cpu[i].item()\n",
    "    axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(f'Train Original\\\\n{class_names[label]}', fontsize=8)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstructed train images\n",
    "    img = recon_train_cpu[i].squeeze()\n",
    "    img = torch.clamp((img + 1) / 2, 0, 1)  # Denormalize and clamp\n",
    "    mse = train_mse[i].item()\n",
    "    axes[1, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'Train Recon\\\\nMSE: {mse:.4f}', fontsize=8)\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Original test images\n",
    "    img = images_test_cpu[i].squeeze()\n",
    "    img = (img + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "    label = labels_test_cpu[i].item()\n",
    "    axes[2, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[2, i].set_title(f'Test Original\\\\n{class_names[label]}', fontsize=8)\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Reconstructed test images\n",
    "    img = recon_test_cpu[i].squeeze()\n",
    "    img = torch.clamp((img + 1) / 2, 0, 1)  # Denormalize and clamp\n",
    "    mse = test_mse[i].item()\n",
    "    axes[3, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[3, i].set_title(f'Test Recon\\\\nMSE: {mse:.4f}', fontsize=8)\n",
    "    axes[3, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute comprehensive evaluation metrics\n",
    "print(\"\\\\n📊 Comprehensive Model Evaluation:\")\n",
    "\n",
    "# 1. Overall reconstruction quality\n",
    "total_train_samples = len(train_loader.dataset)\n",
    "total_test_samples = len(test_loader.dataset)\n",
    "\n",
    "print(f\"\\\\n🎯 Reconstruction Quality:\")\n",
    "print(f\"  Train samples: {total_train_samples}\")\n",
    "print(f\"  Test samples: {total_test_samples}\")\n",
    "print(f\"  Sample train MSE: {train_mse.mean():.6f} ± {train_mse.std():.6f}\")\n",
    "print(f\"  Sample test MSE: {test_mse.mean():.6f} ± {test_mse.std():.6f}\")\n",
    "\n",
    "# 2. Latent space analysis\n",
    "z_train_norm = torch.norm(z_train, dim=1)\n",
    "z_test_norm = torch.norm(z_test, dim=1)\n",
    "\n",
    "print(f\"\\\\n🌌 Latent Space Analysis:\")\n",
    "print(f\"  Latent dimension: {z_train.shape[1]}\")\n",
    "print(f\"  Train latent norm: {z_train_norm.mean():.4f} ± {z_train_norm.std():.4f}\")\n",
    "print(f\"  Test latent norm: {z_test_norm.mean():.4f} ± {z_test_norm.std():.4f}\")\n",
    "print(f\"  Latent range: [{z_train.min():.3f}, {z_train.max():.3f}]\")\n",
    "\n",
    "# 3. GMM evaluation\n",
    "if gmm.converged_:\n",
    "    # Compute log-likelihood of representations\n",
    "    train_log_likelihood = gmm.score_samples(z_train)\n",
    "    test_log_likelihood = gmm.score_samples(z_test)\n",
    "    \n",
    "    print(f\"\\\\n🎲 GMM Evaluation:\")\n",
    "    print(f\"  Number of components: {gmm.n_components}\")\n",
    "    print(f\"  Covariance type: {gmm.covariance_type}\")\n",
    "    print(f\"  Converged: {gmm.converged_}\")\n",
    "    print(f\"  Iterations: {gmm.n_iter_}\")\n",
    "    print(f\"  Train log-likelihood: {train_log_likelihood.mean():.4f} ± {train_log_likelihood.std():.4f}\")\n",
    "    print(f\"  Test log-likelihood: {test_log_likelihood.mean():.4f} ± {test_log_likelihood.std():.4f}\")\n",
    "    \n",
    "    # Component weights\n",
    "    weights = gmm.weights_\n",
    "    print(f\"  Component weights: {weights}\")\n",
    "    print(f\"  Effective components: {(weights > 0.01).sum()} / {len(weights)}\")\n",
    "else:\n",
    "    print(f\"\\\\n⚠️ GMM did not converge (iterations: {gmm.n_iter_})\")\n",
    "\n",
    "print(\"\\\\n✅ Model evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc679d",
   "metadata": {},
   "source": [
    "## 9. Generate Samples from Trained Model\n",
    "\n",
    "Now let's generate new samples using the trained GMM and explore the latent space capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the trained model\n",
    "print(\"🎨 Generating samples from trained DGD model...\")\n",
    "\n",
    "if gmm.converged_:\n",
    "    with torch.no_grad():\n",
    "        # 1. Sample from GMM\n",
    "        n_samples = 32\n",
    "        z_samples, component_labels = gmm.sample(n_samples)\n",
    "        \n",
    "        # Generate images from samples\n",
    "        generated_images = model.decoder(z_samples)\n",
    "        \n",
    "        print(f\"✓ Generated {n_samples} samples from GMM\")\n",
    "        print(f\"✓ Sample shape: {generated_images.shape}\")\n",
    "        print(f\"✓ Component distribution: {np.bincount(component_labels.cpu().numpy())}\")\n",
    "        \n",
    "        # Visualize generated samples\n",
    "        fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "        fig.suptitle('Generated Samples from Trained DGD Model', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        generated_images_cpu = generated_images.cpu()\n",
    "        component_labels_cpu = component_labels.cpu()\n",
    "        \n",
    "        for i in range(min(32, n_samples)):\n",
    "            row = i // 8\n",
    "            col = i % 8\n",
    "            \n",
    "            img = generated_images_cpu[i].squeeze()\n",
    "            img = torch.clamp((img + 1) / 2, 0, 1)  # Denormalize and clamp\n",
    "            component = component_labels_cpu[i].item()\n",
    "            \n",
    "            axes[row, col].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[row, col].set_title(f'Sample {i+1}\\nComp: {component}', fontsize=8)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Sample from each GMM component separately\n",
    "        print(\"\\n🎯 Generating samples from individual GMM components...\")\n",
    "        \n",
    "        def sample_from_component(gmm, n_samples, component_idx):\n",
    "            \"\"\"Sample n_samples from a specific GMM component.\"\"\"\n",
    "            # Get the mean and covariance for the specific component\n",
    "            mean = gmm.means_[component_idx]\n",
    "            \n",
    "            # Handle different covariance types\n",
    "            if gmm.covariance_type == 'full':\n",
    "                cov = gmm.covariances_[component_idx]\n",
    "            elif gmm.covariance_type == 'diag':\n",
    "                cov = torch.diag_embed(gmm.covariances_[component_idx])\n",
    "            elif gmm.covariance_type == 'spherical':\n",
    "                cov = torch.eye(gmm.n_features, device=gmm.device) * gmm.covariances_[component_idx]\n",
    "            elif gmm.covariance_type == 'tied_full':\n",
    "                cov = gmm.covariances_\n",
    "            elif gmm.covariance_type == 'tied_diag':\n",
    "                cov = torch.diag_embed(gmm.covariances_)\n",
    "            elif gmm.covariance_type == 'tied_spherical':\n",
    "                cov = torch.eye(gmm.n_features, device=gmm.device) * gmm.covariances_\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported covariance type: {gmm.covariance_type}\")\n",
    "            \n",
    "            # Sample from the multivariate normal distribution\n",
    "            dist = torch.distributions.MultivariateNormal(mean, cov)\n",
    "            samples = dist.sample((n_samples,))\n",
    "            return samples\n",
    "        \n",
    "        # Generate samples from each component\n",
    "        n_per_component = 4\n",
    "        fig, axes = plt.subplots(gmm.n_components, n_per_component, figsize=(n_per_component*2, gmm.n_components*2))\n",
    "        fig.suptitle('Samples by GMM Component', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        for comp in range(gmm.n_components):\n",
    "            # Sample from specific component\n",
    "            z_comp = sample_from_component(gmm, n_per_component, comp)\n",
    "            imgs_comp = model.decoder(z_comp)\n",
    "            \n",
    "            for j in range(n_per_component):\n",
    "                img = imgs_comp[j].cpu().squeeze()\n",
    "                img = torch.clamp((img + 1) / 2, 0, 1)\n",
    "                \n",
    "                if gmm.n_components == 1:\n",
    "                    axes[j].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "                    axes[j].set_title(f'Comp {comp}, Sample {j+1}', fontsize=8)\n",
    "                    axes[j].axis('off')\n",
    "                else:\n",
    "                    axes[comp, j].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "                    axes[comp, j].set_title(f'Comp {comp}, Sample {j+1}', fontsize=8)\n",
    "                    axes[comp, j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 3. Latent space interpolation\n",
    "        print(\"\\n🌈 Demonstrating latent space interpolation...\")\n",
    "        \n",
    "        # Get two random samples from the latent space\n",
    "        z1, _ = gmm.sample(1)\n",
    "        z2, _ = gmm.sample(1)\n",
    "        \n",
    "        # Create interpolation\n",
    "        n_steps = 10\n",
    "        alphas = torch.linspace(0, 1, n_steps).to(device)\n",
    "        \n",
    "        interpolated_images = []\n",
    "        for alpha in alphas:\n",
    "            z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "            img_interp = model.decoder(z_interp)\n",
    "            interpolated_images.append(img_interp)\n",
    "        \n",
    "        # Visualize interpolation\n",
    "        fig, axes = plt.subplots(1, n_steps, figsize=(n_steps*1.5, 2))\n",
    "        fig.suptitle('Latent Space Interpolation', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for i, img in enumerate(interpolated_images):\n",
    "            img_cpu = img.cpu().squeeze()\n",
    "            img_cpu = torch.clamp((img_cpu + 1) / 2, 0, 1)\n",
    "            \n",
    "            axes[i].imshow(img_cpu, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i].set_title(f'α={alphas[i]:.1f}', fontsize=8)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 4. Random sampling comparison\n",
    "        print(\"\\n🎲 Comparing GMM sampling vs random sampling...\")\n",
    "        \n",
    "        # GMM samples\n",
    "        z_gmm, _ = gmm.sample(8)\n",
    "        imgs_gmm = model.decoder(z_gmm)\n",
    "        \n",
    "        # Random Gaussian samples\n",
    "        z_random = torch.randn(8, config.model.representation.n_features).to(device)\n",
    "        imgs_random = model.decoder(z_random)\n",
    "        \n",
    "        # Visualize comparison\n",
    "        fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "        fig.suptitle('GMM Sampling vs Random Gaussian Sampling', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for i in range(8):\n",
    "            # GMM samples\n",
    "            img = imgs_gmm[i].cpu().squeeze()\n",
    "            img = torch.clamp((img + 1) / 2, 0, 1)\n",
    "            axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[0, i].set_title(f'GMM {i+1}', fontsize=8)\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Random samples\n",
    "            img = imgs_random[i].cpu().squeeze()\n",
    "            img = torch.clamp((img + 1) / 2, 0, 1)\n",
    "            axes[1, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[1, i].set_title(f'Random {i+1}', fontsize=8)\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"✅ Sample generation completed!\")\n",
    "        print(f\"✓ GMM sampling produces more structured samples\")\n",
    "        print(f\"✓ Random sampling may produce less realistic samples\")\n",
    "        print(f\"✓ Interpolation shows smooth transitions in latent space\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ GMM did not converge - cannot generate meaningful samples\")\n",
    "    print(\"💡 Try training for more epochs or adjusting GMM parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb07fe9",
   "metadata": {},
   "source": [
    "## 10. Save and Export Model\n",
    "\n",
    "Finally, let's save the trained model components and demonstrate how to load them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model components\n",
    "print(\"💾 Saving trained DGD model components...\")\n",
    "\n",
    "# Create model save directory\n",
    "model_dir = project_root / \"models\" / \"dgd_demo\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Model save directory: {model_dir}\")\n",
    "\n",
    "# 1. Save model state dictionaries\n",
    "torch.save(model.decoder.state_dict(), model_dir / \"decoder.pth\")\n",
    "torch.save(rep_layer.state_dict(), model_dir / \"train_representation.pth\")\n",
    "torch.save(test_rep_layer.state_dict(), model_dir / \"test_representation.pth\")\n",
    "\n",
    "print(\"✓ Saved PyTorch model state dictionaries\")\n",
    "\n",
    "# 2. Save GMM model\n",
    "import pickle\n",
    "with open(model_dir / \"gmm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gmm, f)\n",
    "\n",
    "print(\"✓ Saved GMM model\")\n",
    "\n",
    "# 3. Save configuration\n",
    "OmegaConf.save(config, model_dir / \"config.yaml\")\n",
    "\n",
    "print(\"✓ Saved configuration\")\n",
    "\n",
    "# 4. Save training results\n",
    "training_results = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'recon_train_losses': trainer.recon_train_losses,\n",
    "    'recon_test_losses': trainer.recon_test_losses,\n",
    "    'gmm_train_losses': trainer.gmm_train_losses,\n",
    "    'gmm_test_losses': trainer.gmm_test_losses,\n",
    "    'epoch_times': trainer.epoch_times,\n",
    "    'final_train_loss': results['final_train_loss'],\n",
    "    'final_test_loss': results['final_test_loss'],\n",
    "    'total_time': results['total_time']\n",
    "}\n",
    "\n",
    "torch.save(training_results, model_dir / \"training_results.pth\")\n",
    "\n",
    "print(\"✓ Saved training results\")\n",
    "\n",
    "# 5. Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'DGD',\n",
    "    'dataset': config.data.dataset,\n",
    "    'epochs_trained': len(train_losses),\n",
    "    'latent_dim': config.model.representation.n_features,\n",
    "    'decoder_params': sum(p.numel() for p in model.decoder.parameters()),\n",
    "    'rep_params': sum(p.numel() for p in rep_layer.parameters()),\n",
    "    'gmm_components': gmm.n_components,\n",
    "    'gmm_converged': gmm.converged_,\n",
    "    'training_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'device_used': str(device),\n",
    "    'pytorch_version': torch.__version__\n",
    "}\n",
    "\n",
    "torch.save(metadata, model_dir / \"metadata.pth\")\n",
    "\n",
    "print(\"✓ Saved model metadata\")\n",
    "\n",
    "# List all saved files\n",
    "saved_files = list(model_dir.glob(\"*\"))\n",
    "print(f\"\\\\n📁 Saved files ({len(saved_files)} total):\")\n",
    "for file in saved_files:\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {file.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"🔄 Demonstrating Model Loading...\")\n",
    "\n",
    "# Demonstrate loading the saved model\n",
    "def load_dgd_model(model_dir, device):\n",
    "    \"\"\"Load a saved DGD model from directory.\"\"\"\n",
    "    print(f\"Loading DGD model from {model_dir}...\")\n",
    "    \n",
    "    # Load configuration\n",
    "    config_loaded = OmegaConf.load(model_dir / \"config.yaml\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata = torch.load(model_dir / \"metadata.pth\", map_location=device)\n",
    "    \n",
    "    # Recreate decoder\n",
    "    decoder_loaded = ConvDecoder(\n",
    "        latent_dim=config_loaded.model.representation.n_features,\n",
    "        hidden_dims=config_loaded.model.decoder.hidden_dims,\n",
    "        output_channels=config_loaded.model.decoder.output_channels,\n",
    "        output_size=config_loaded.model.decoder.output_size,\n",
    "        use_batch_norm=config_loaded.model.decoder.use_batch_norm,\n",
    "        activation=config_loaded.model.decoder.activation,\n",
    "        final_activation=config_loaded.model.decoder.final_activation,\n",
    "        dropout_rate=config_loaded.model.decoder.dropout_rate,\n",
    "        init_size=config_loaded.model.decoder.init_size\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load decoder weights\n",
    "    decoder_loaded.load_state_dict(torch.load(model_dir / \"decoder.pth\", map_location=device))\n",
    "    \n",
    "    # Load GMM\n",
    "    with open(model_dir / \"gmm.pkl\", \"rb\") as f:\n",
    "        gmm_loaded = pickle.load(f)\n",
    "    \n",
    "    # Recreate representation layers (for new data)\n",
    "    rep_loaded = RepresentationLayer(\n",
    "        dim=config_loaded.model.representation.n_features,\n",
    "        n_samples=1000,  # Can be changed for new datasets\n",
    "        dist=config_loaded.model.representation.distribution,\n",
    "        dist_params={'radius': config_loaded.model.representation.radius} if hasattr(config_loaded.model.representation, 'radius') else {},\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Create DGD model\n",
    "    model_loaded = DGD(decoder_loaded, rep_loaded, gmm_loaded)\n",
    "    \n",
    "    print(\"✓ Model loaded successfully!\")\n",
    "    return model_loaded, config_loaded, metadata\n",
    "\n",
    "# Load the model\n",
    "loaded_model, loaded_config, loaded_metadata = load_dgd_model(model_dir, device)\n",
    "\n",
    "print(\"✅ Model loading demonstration completed!\")\n",
    "print(f\"✓ Loaded model trained for {loaded_metadata['epochs_trained']} epochs\")\n",
    "print(f\"✓ Model parameters: {loaded_metadata['decoder_params']:,}\")\n",
    "print(f\"✓ GMM converged: {loaded_metadata['gmm_converged']}\")\n",
    "print(f\"✓ Training date: {loaded_metadata['training_date']}\")\n",
    "\n",
    "# Test the loaded model with a sample\n",
    "print(\"\\\\n🧪 Testing loaded model...\")\n",
    "with torch.no_grad():\n",
    "    # Sample from loaded GMM\n",
    "    z_test_load, _ = loaded_model.gmm.sample(4)\n",
    "    img_test_load = loaded_model.decoder(z_test_load)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "    fig.suptitle('Samples from Loaded Model', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    for i in range(4):\n",
    "        img = img_test_load[i].cpu().squeeze()\n",
    "        img = torch.clamp((img + 1) / 2, 0, 1)\n",
    "        axes[i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f'Sample {i+1}', fontsize=8)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Loaded model generates samples correctly!\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"🎉 DGD Training Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\\\n📋 Summary:\")\n",
    "print(f\"✅ Trained DGD model for {len(train_losses)} epochs\")\n",
    "print(f\"✅ Final train loss: {results['final_train_loss']:.6f}\")\n",
    "print(f\"✅ Final test loss: {results['final_test_loss']:.6f}\")\n",
    "print(f\"✅ GMM fitted with {gmm.n_components} components\")\n",
    "print(f\"✅ Model saved to: {model_dir}\")\n",
    "print(f\"✅ Model loading verified\")\n",
    "print(f\"✅ Sample generation working\")\n",
    "\n",
    "print(\"\\\\n🚀 Next Steps:\")\n",
    "print(\"• Try different configurations (latent dimensions, architectures)\")\n",
    "print(\"• Experiment with different datasets\")\n",
    "print(\"• Adjust GMM parameters for better clustering\")\n",
    "print(\"• Use longer training for better convergence\")\n",
    "print(\"• Explore different representation distributions\")\n",
    "print(\"• Use ClearML for experiment tracking and comparison\")\n",
    "\n",
    "if task:\n",
    "    print(f\"\\\\n📊 View results in ClearML: Task ID {task.id}\")\n",
    "    # Mark task as completed\n",
    "    task.mark_completed()\n",
    "\n",
    "print(\"\\\\n🎯 DGDTrainer Usage Demonstrated Successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
